{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwEhYC-H-Ajy"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBZ_loKe-P2f",
        "outputId": "e520c6e5-56a9-4c9b-ded1-6dcceb0ed0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+------+\n",
            "|customer_id|purchase_date|amount|\n",
            "+-----------+-------------+------+\n",
            "|        101|   2025-01-03|   250|\n",
            "|        102|   2025-01-01|   150|\n",
            "|        103|   2025-01-04|   500|\n",
            "+-----------+-------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName(\"myApp\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (101, \"2025-01-03\", 250),\n",
        "    (101, \"2025-01-05\", 300),\n",
        "    (102, \"2025-01-01\", 150),\n",
        "    (102, \"2025-01-02\", 200),\n",
        "    (103, \"2025-01-04\", 500)\n",
        "]\n",
        "\n",
        "columns = [\"customer_id\", \"purchase_date\", \"amount\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"purchase_date\")\n",
        "\n",
        "df = (\n",
        "    df.withColumn(\"row_num\", row_number().over(windowSpec))\n",
        "      .filter(col(\"row_num\") == 1)\n",
        "      .drop(\"row_num\")\n",
        ")\n",
        "\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "xe1PDsRtrd8t",
        "outputId": "13fa29dd-6840-42a1-ae74-dbb0998488b3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nSELECT emp_id, \\n       COUNT(*) - 1 AS salary_change_count\\nFROM (\\n    SELECT emp_id, salary, \\n           ROW_NUMBER() OVER (PARTITION BY emp_id ORDER BY effective_date) AS rn\\n    FROM employee_salaries\\n) t\\nGROUP BY emp_id\\nHAVING COUNT(DISTINCT salary) > 1;\\n\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "SELECT emp_id,\n",
        "       COUNT(*) - 1 AS salary_change_count\n",
        "FROM (\n",
        "    SELECT emp_id, salary,\n",
        "           ROW_NUMBER() OVER (PARTITION BY emp_id ORDER BY effective_date) AS rn\n",
        "    FROM employee_salaries\n",
        ") t\n",
        "GROUP BY emp_id\n",
        "HAVING COUNT(DISTINCT salary) > 1;\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaugkc3msX2m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
